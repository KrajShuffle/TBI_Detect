# Portable & Inexpensive Fluorescence Imaging for Traumatic Brain Injury

This is a group project comprising of Karthik Raj, Justin Yeung, Akash Canjels, and William Livingston with mentorship from Dr. Ester Kwon and Julia Kudryashev. This project aims to develop an objective approach for detecting Traumatic Brain Injury (TBI) while addressing current time-intensive and lack of flexibility issues with commmon TBI detection methods. I worked on the circuit design, setting up both the Raspberry Pi & infrared camera, and designing a simple framework for capturing images of fluorophore emissions from either the 490 nm or 770 nm flurophores. 

## Abstract
Heightened enzymatic activity of proteases Calpain-1 (CAPN1) and Matrix Metallopeptidase 9 (MMP9) are characteristic biomarkers of traumatic brain injury (TBI). Activity of these proteases has been shown to increase with severity of TBI, and is thus a suitable target for in-vitro diagnosis. We seek to develop an inexpensive, rapid, point-of-care diagnostic device using a lateral flow assay (LFA) and a portable imaging device. Working with the Kwon lab, we have developed an in-vitro fluorescent diagnostic system for injectable peptide probes specific to CAPN1 and MMP9. Our LFA can detect cleaved residues within a range of 20-100 nM using the LI-COR Odyssey Platform, and our imaging device is able to capture fluorescent signals at ~490 nm and ~770 nm. There are multiple future directions of this project, including optimization of the LFA sample pad, characterization of the LFA-imaging device, automating image capture to signal readout, and multiplexing the LFA and imaging device.

## Fluorescence Imaging of TBI-Associated Biomarkers Device Construction

The darkbox or optical setup excites and images our fluorophores of interest by combining LEDs and dichroic filters to isolate specific excitation and absorption wavelengths. The general process begins when a specific wavelength band of the LED emission is reflected by the dichroic filter to excite the fluorophore. Then, the fluorophore emission is isolated as it travels down through the dichroic filter. Lastly, an image of the emission is taken by a camera placed directly below the dichroic filter. This all occurs in a dark environment created by the darkbox.

The darkbox is composed of black acrylic with a removable top, which acts as an access point for the user. From top to bottom, there is a stage, filter wheel, and a camera placed collinearly. The stage, platform with a rectangular slit, is where the user places their lateral flow strip face down with the test and control lines in the opening. Below the stage, there is a filter wheel containing 2 dichroic filters that are unique to the respective fluorophore. Directly below the filter wheel, there is a camera which can capture IR and non-IR fluorophore emissions and is in the line of view of both the dichroic filter and the slit containing both the test and control lines of the lateral flow strip. Along the sides of the darkbox, there are LEDs of different wavelengths (490 nm and 770 nm) that are perpendicular to both the camera and the stage holding the lateral flow strip. Lastly, in the corner of the darkbox, there is a Raspberry Pi connected to the camera and each respective combination of LED and resistor through female to female wires. 

## Overview of Script Used for Capture of Fluorophore Emission

The Raspberry Pi is the sole regulator of the procedure resulting in an image of the fluorophore emission in low light. When running the script, the user calls the script alongside an argument (either 490 or 770) denoting which fluorophore's emission is going to be captured. For reference, the maxima excitation wavelength for the FAM fluorophore is ~490 nm and the maxima excitation wavelength for the LICOR fluorophore is ~770 nm. Thus, by passing the value of either 490 or 770, you are determining which fluorophore will be excited and the corresponding LED that will be turned on to excite that fluorophore.  

Within the flor_image_emiss.py Python script,the Pi first notes the respective time of the image capture and stores it as a string. Then, the Pi initializes the camera with the desired ISO, shutter speed, resolution, and image rotation. ISO determines the camera’s sensitivity to light. Shutter speed determines the amount of time the camera’s shutter is open, and thus the amount of light the camera takes in. All of these settings have been fine-tuned through iterations of capturing images of fluorophore emission. There are other settings required for image capture, but they are automatically set by the Pi during its 30 second pause. Then, based on the passed argument, the corresponding LED switches on, camera takes an image, and the LED switches off. The filename of the image is the timestamp noted in the beginning. With this setup, you can rapidly take images without concern for overwriting prior images, which is key for rapid testing and optimization.

## Capturing Images of Fluorophore Emissions With Mobile Device

If you are interested in capturing and viewing images of fluorophore emissions with your mobile device (iOS or Android), you can simply use the Raspcontroller app to do so. First, make sure your phone and the Raspberry Pi are connected to the same WIFI network, and connect to the Raspberry Pi. I have set up my Raspcontroller to have 2 default commands that initate image capture of either the ~490 nm fluorophore or ~770 nm fluorophore. These commands appear as buttons, but on the Linux command line calls and runs the flor_image_emiss.py Python script with either the value of 490 or 770 passed as a separate parameter. Therefore, with this setup, you no longer need to rely on using your laptop and Remote Desktop to interface with the Raspberry Pi and trigger the image capture of the respective fluorophore emission. Now, you can simply use your mobile device and a button to do so. You can even view the saved images on your device by going to the image's saved directory to download the image onto your mobile device.

## Changes Made from Initial Design

The general ideology defining the process for fluorophore excitation and the capture of its emission did not change from the initial proposal. The darkbox still utilizes a LED as a light source, a dichroic filter reflects a desired wavelength band of the LED illumination to the fluorophore and isolates the fluorophore emission, and the camera is still used to capture the fluorophore emission. 

However, there were adjustments made within the box to move both the LED and camera closer to the lens wheel. These adjustments were made because our initial iteration of testing the imaging system prototype resulted in an image capture of lower than expected fluorophore emission intensity. For context, I imaged an undiluted drop of FAM and the FAM emission captured from the imaging setup greatly paled in comparison to the FAM emission captured from a fluorescent microscope in the Kwon lab. I assumed a major reason for this was a result of the light emission of the LED and the fluorophore traveling such far distances in our imaging setup that their detected intensities are far less than expected. Since light intensity decreases as a factor of distance squared, by moving both the LED and the camera closer, I am expecting a greater intensity in the fluorophore excitation and captured fluorophore emission. Akash and I also placed a cylinder around the camera to prevent LED ambient light from affecting the camera’s perception of fluorophore emission. Lastly, Akash and I identified the position in which the stage is most aligned with the camera (allowing for max capture of fluorophore emission) and marked the location to ensure the stage is oriented in this optimal direction.
